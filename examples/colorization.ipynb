{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6d6fdd69",
            "metadata": {},
            "source": [
                "<pre style=\"text-align: right; width: 100%; font-size: 0.75em; line-height: 0.75em;\">\n",
                "+ ------------------------- + <br>\n",
                "| 28/04/2025                | <br>\n",
                "| Héctor Tablero Díaz       | <br>\n",
                "| Álvaro Martínez Gamo      | <br>\n",
                "+ ------------------------- + \n",
                "</pre>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "05256d2e",
            "metadata": {},
            "source": [
                "# **Colorization**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4f70db8b",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('./..')\n",
                "\n",
                "import os\n",
                "\n",
                "import torch\n",
                "from torch.utils.data import Subset\n",
                "from torchvision import datasets, transforms\n",
                "from torchvision.transforms import ToTensor\n",
                "\n",
                "from image_gen import GenerativeModel\n",
                "from image_gen.samplers import EulerMaruyama\n",
                "from image_gen.diffusion import VarianceExploding\n",
                "\n",
                "from image_gen.visualization import display_images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9b32bcbe",
            "metadata": {},
            "outputs": [],
            "source": [
                "epochs = 500\n",
                "class_id = 1\n",
                "seed = 123"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "925858fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "\n",
                "data = datasets.CIFAR10(\n",
                "    root='data',\n",
                "    train=True,\n",
                "    download=True,\n",
                "    transform=ToTensor()\n",
                ")\n",
                "\n",
                "# Select a subset to speed up the training process\n",
                "targets = torch.tensor(data.targets)\n",
                "idx = (targets == class_id).nonzero().flatten()\n",
                "data = Subset(data, idx)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8a7cfbf6",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = GenerativeModel(\n",
                "    diffusion=VarianceExploding,\n",
                "    sampler=EulerMaruyama\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "03ffa73f",
            "metadata": {},
            "outputs": [],
            "source": [
                "filename = f'saved_models/cifar10_{class_id}_ve_{epochs}e.pth'\n",
                "\n",
                "if os.path.isfile(filename):\n",
                "    model.load(filename)\n",
                "else:\n",
                "    model.train(data, epochs=epochs)\n",
                "    # Tip: Save the models for them to be accessible through the dashboard\n",
                "    model.save(filename)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9113ff2c",
            "metadata": {},
            "source": [
                "## **Overview**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "980d19c7",
            "metadata": {},
            "source": [
                "Grayscale-to-color synthesis using YUV-space luminance guidance.\n",
                "\n",
                "Key features:\n",
                "- Requires 3-channel diffusion model\n",
                "- Preserves original luminance values\n",
                "- Generates plausible color variations\n",
                "- Interactive evolution visualization"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "db0f1444",
            "metadata": {},
            "source": [
                "## **Parameters**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "78ee8307",
            "metadata": {},
            "source": [
                "| Parameter | Type | Default | Description |\n",
                "|-----------|------|---------|-------------|\n",
                "| `x` | Tensor | - | Input grayscale image (1 or 3 channels) |\n",
                "| `n_steps` | int | 500 | Reverse process steps |\n",
                "| `seed` | int | None | Random seed |\n",
                "| `class_labels` | Tensor | None | Optional class conditioning |\n",
                "| `progress_callback` | function | None | Generation progress handler |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc7c1140",
            "metadata": {},
            "source": [
                "## **Usage Examples**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b7551d63",
            "metadata": {},
            "source": [
                "### **Basic Colorization**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3503b7c7",
            "metadata": {},
            "source": [
                "Colorize a grayscale image:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "deaeeca0",
            "metadata": {},
            "outputs": [],
            "source": [
                "generated_image = model.generate(num_samples=1, seed=seed)\n",
                "gray_image = torch.mean(generated_image, dim=1, keepdim=True)\n",
                "display_images(generated_image)\n",
                "display_images(gray_image)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "971eb831",
            "metadata": {},
            "outputs": [],
            "source": [
                "colorized = model.colorize(gray_image, seed=seed)\n",
                "display_images(colorized)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c97b1442",
            "metadata": {},
            "source": [
                "### **Multiple Variations**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fc449075",
            "metadata": {},
            "source": [
                "Generate different color hypotheses:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a24cd184",
            "metadata": {},
            "outputs": [],
            "source": [
                "gray_batch = gray_image.repeat(16, 1, 1, 1)\n",
                "colorized_batch = model.colorize(gray_batch, seed=seed)\n",
                "display_images(colorized_batch)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abd34ac7",
            "metadata": {},
            "source": [
                "## **Implementation Details**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3126fb5b",
            "metadata": {},
            "source": [
                "The colorization process:\n",
                "\n",
                "1. **YUV Conversion**: Convert grayscale to YUV space\n",
                "2. **UV Initialization**: Randomize chrominance channels\n",
                "3. **Luminance Enforcement**: Gradually blend generated colors with original luminance\n",
                "4. **RGB Conversion**: Final result in standard color space\n",
                "\n",
                "Key equation during sampling:\n",
                "$$ Y_{t} = (1-\\alpha)Y^{\\text{generated}} + \\alpha Y^{\\text{original}} $$\n",
                "where $\\alpha$ decreases linearly from 1 to 0"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa238092",
            "metadata": {},
            "source": [
                "## **Important Notes**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa4519d2",
            "metadata": {},
            "source": [
                "- Model **must** be initialized with 3 channels\n",
                "- Input can be 1-channel (grayscale) or 3-channel (RGB)\n",
                "- Dashboard expects grayscale PNG inputs\n",
                "- Output values clamped to [0,1] range\n",
                "- Higher steps (500+) improve color coherence"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
