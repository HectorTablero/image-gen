{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a2d0fc1a",
            "metadata": {},
            "source": [
                "<pre style=\"text-align: right; width: 100%; font-size: 0.75em; line-height: 0.75em;\">\n",
                "+ ------------------------- + <br>\n",
                "| 03/05/2025                | <br>\n",
                "| Héctor Tablero Díaz       | <br>\n",
                "| Álvaro Martínez Gamo      | <br>\n",
                "+ ------------------------- + \n",
                "</pre>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8afee7ef",
            "metadata": {},
            "source": [
                "# **Evaluation (Metrics)**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bf439bbd",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('./..')\n",
                "\n",
                "import os\n",
                "\n",
                "import torch\n",
                "from torch import Tensor\n",
                "from torch.utils.data import Subset, DataLoader\n",
                "from torchvision import datasets, transforms\n",
                "import numpy as np\n",
                "\n",
                "from image_gen import GenerativeModel\n",
                "from image_gen.samplers import ExponentialIntegrator\n",
                "from image_gen.diffusion import VariancePreserving\n",
                "from image_gen.noise import LinearNoiseSchedule\n",
                "from image_gen.metrics import BaseMetric, BitsPerDimension, FrechetInceptionDistance, InceptionScore\n",
                "\n",
                "from typing import Dict, List, Optional, Union\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from image_gen.visualization import display_images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "da1756c2",
            "metadata": {},
            "outputs": [],
            "source": [
                "epoch_values = [1, 5, 25, 100]\n",
                "train_percent = 0.8\n",
                "digit = 3\n",
                "class_id = 1\n",
                "seed = 1234"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "81d419b3",
            "metadata": {},
            "outputs": [],
            "source": [
                "data_mnist = datasets.MNIST(\n",
                "    root='data',\n",
                "    train=True,\n",
                "    download=True,\n",
                "    transform=transforms.ToTensor()\n",
                ")\n",
                "indices_digit = torch.where(data_mnist.targets == digit)[0]\n",
                "data_mnist = Subset(data_mnist, indices_digit)\n",
                "train_size_mnist = int(train_percent * len(data_mnist))\n",
                "test_size_mnist = len(data_mnist) - train_size_mnist\n",
                "data_mnist_train, data_mnist_test = torch.utils.data.random_split(data_mnist, [train_size_mnist, test_size_mnist])\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
                "])\n",
                "data_cifar = datasets.CIFAR10(\n",
                "    root='data',\n",
                "    train=True,\n",
                "    download=True,\n",
                "    transform=transform\n",
                ")\n",
                "indices_class_id = torch.where(torch.tensor(data_cifar.targets) == class_id)[0]\n",
                "data_cifar = Subset(data_cifar, indices_class_id)\n",
                "train_size_cifar = int(train_percent * len(data_cifar))\n",
                "test_size_cifar = len(data_cifar) - train_size_cifar\n",
                "data_cifar_train, data_cifar_test = torch.utils.data.random_split(data_cifar, [train_size_cifar, test_size_cifar])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e7c63da0",
            "metadata": {},
            "outputs": [],
            "source": [
                "trained_models_mnist = []\n",
                "trained_models_cifar = []\n",
                "\n",
                "for epochs in epoch_values:\n",
                "    model = GenerativeModel(\n",
                "        diffusion=VariancePreserving,\n",
                "        noise_schedule=LinearNoiseSchedule,\n",
                "        sampler=ExponentialIntegrator\n",
                "    )\n",
                "    # The \"_train\" part is added to avoid loading models that have been trained with the full dataset (including test data)\n",
                "    filename = f'saved_models/mnist_{digit}_train_vp-lin_{epochs}e.pth'\n",
                "    if os.path.isfile(filename):\n",
                "        model.load(filename)\n",
                "    else:\n",
                "        model.train(data_mnist_train, epochs=epochs)\n",
                "        model.save(filename)\n",
                "    trained_models_mnist.append(model)\n",
                "\n",
                "    model = GenerativeModel(\n",
                "        diffusion=VariancePreserving,\n",
                "        noise_schedule=LinearNoiseSchedule,\n",
                "        sampler=ExponentialIntegrator\n",
                "    )\n",
                "    # The \"_train\" part is added to avoid loading models that have been trained with the full dataset (including test data)\n",
                "    filename = f'saved_models/cifar10_{class_id}_train_vp-lin_{epochs}e.pth'\n",
                "    if os.path.isfile(filename):\n",
                "        model.load(filename)\n",
                "    else:\n",
                "        model.train(data_cifar_train, epochs=epochs)\n",
                "        model.save(filename)\n",
                "    trained_models_cifar.append(model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6d56676d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_scores(scores: Dict[str, List[float]], metrics: List[BaseMetric], title: Optional[str] = None):\n",
                "    fig, axes = plt.subplots(1, len(metrics), figsize=(6 * len(metrics), 5))\n",
                "    if len(metrics) == 1:\n",
                "        axes = [axes]\n",
                "\n",
                "    for ax, metric in zip(axes, metrics):\n",
                "        name = metric.name\n",
                "        values = scores[name]\n",
                "        \n",
                "        ax.plot(epoch_values, values, 'o-', label=name, color='blue')\n",
                "        ax.set_title(f\"{name} ({'lower' if metric.is_lower_better else 'higher'} is better)\")\n",
                "        ax.set_xlabel('Training Epochs')\n",
                "        ax.set_ylabel(\"Value\")\n",
                "        ax.set_xscale(\"log\")\n",
                "        ax.grid(True)\n",
                "        \n",
                "        # Find best point\n",
                "        best_idx = int(np.argmin(values) if metric.is_lower_better else np.argmax(values))\n",
                "        best_epoch = epoch_values[best_idx]\n",
                "        best_value = values[best_idx]\n",
                "        ax.plot(best_epoch, best_value, 'ro')\n",
                "        ax.annotate(f'Best: {best_value:.3f}', \n",
                "                    xy=(best_epoch, best_value), \n",
                "                    xytext=(best_epoch, best_value + 0.05 * (max(values) - min(values))),\n",
                "                    arrowprops=dict(arrowstyle='->', color='black'))\n",
                "        \n",
                "    plt.suptitle(title, fontsize=16)\n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9113ff2c",
            "metadata": {},
            "source": [
                "## **Overview**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "33f23fc7",
            "metadata": {},
            "source": [
                "A dict with scores can be obtained by using the following code:\n",
                "\n",
                "> ```python\n",
                "> # Get scores for generated samples\n",
                "> scores = model.score(\n",
                ">     real=real_data, \n",
                ">     generated=fake_samples,\n",
                ">     scores=[\"bpd\", \"fid\", \"is\"]\n",
                "> )\n",
                "> ```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9339d5e1",
            "metadata": {},
            "source": [
                "**Implemented Metrics:**\n",
                "| Metric | Full Name | Range | Ideal | Best For |\n",
                "|--------|-----------|-------|-------|----------|\n",
                "| [BPD](#bpd) | Bits Per Dimension | $[0, \\infty)$ | Lower | Density Estimation |\n",
                "| [FID](#fid) | Fréchet Inception Distance | $[0, \\infty)$ | Lower | Image Quality |\n",
                "| [IS](#is) | Inception Score | $[1, \\infty)$ | Higher | Diversity |"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dc7c1140",
            "metadata": {},
            "source": [
                "### <span id=\"bpd\">**Bits Per Dimension (BPD)**</span>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "15c6f49c",
            "metadata": {},
            "source": [
                "**Measurement:** Negative log-likelihood in bits/dimension  \n",
                "**Interpretation:**\n",
                "- Lower = Better density modeling\n",
                "- Sensitive to training stability\n",
                "- Values < 3.0 generally acceptable"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b7551d63",
            "metadata": {},
            "source": [
                "### <span id=\"fid\">**Fréchet Inception Distance (FID)**</span>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "12cfe6d3",
            "metadata": {},
            "source": [
                "**Measurement:** Distance between real/fake feature distributions  \n",
                "**Interpretation:**\n",
                "- Lower = Better visual quality\n",
                "- < 50 = Excellent\n",
                "- 50-100 = Good\n",
                "- \\> 100 = Needs improvement"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c97b1442",
            "metadata": {},
            "source": [
                "### <span id=\"is\">**Inception Score (IS)**</span>"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9df17bd9",
            "metadata": {},
            "source": [
                "**Measurement:** KL divergence between conditional and marginal class distributions  \n",
                "**Interpretation:**\n",
                "- Higher = Better diversity/quality\n",
                "- \\> 10 = Excellent\n",
                "- 5-10 = Good\n",
                "- < 5 = Poor diversity"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "637fcd1a",
            "metadata": {},
            "source": [
                "### **Metric Comparison by Epochs**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "37277eee",
            "metadata": {},
            "source": [
                "#### CIFAR10"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "85de6d8a",
            "metadata": {},
            "outputs": [],
            "source": [
                "scores_cifar = {}\n",
                "\n",
                "for model in trained_models_cifar:\n",
                "    metrics = [BitsPerDimension(model), FrechetInceptionDistance(model), InceptionScore(model)]\n",
                "    samples = model.generate(16, seed=seed)\n",
                "    scores = model.score(data_cifar_test, samples, metrics=metrics)\n",
                "    for score in scores:\n",
                "        if score not in scores_cifar:\n",
                "            scores_cifar[score] = []\n",
                "        scores_cifar[score].append(scores[score])\n",
                "\n",
                "# Show the last generated images\n",
                "display_images(samples)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bab16b65",
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_scores(scores_cifar, metrics, \"CIFAR10 - Scores vs Training Epochs\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a39e7b9c",
            "metadata": {},
            "source": [
                "#### MNIST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce286c0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "scores_mnist = {}\n",
                "\n",
                "for model in trained_models_mnist:\n",
                "    metrics = [BitsPerDimension(model), FrechetInceptionDistance(model), InceptionScore(model)]\n",
                "    samples = model.generate(16, seed=seed)\n",
                "    scores = model.score(data_mnist_test, samples, metrics=metrics)\n",
                "    for score in scores:\n",
                "        if score not in scores_mnist:\n",
                "            scores_mnist[score] = []\n",
                "        scores_mnist[score].append(scores[score])\n",
                "\n",
                "# Show the last generated images\n",
                "display_images(samples)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f70ce960",
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_scores(scores_mnist, metrics, \"MNIST - Scores vs Training Epochs\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c6a055f5",
            "metadata": {},
            "source": [
                "Contrary to the expectations from the `CIFAR10` test, where scores got better the longer the model had trained for, in `MNIST` we find that `BitsPerDimension` and `InceptionScore` don't show the best results with the most epochs.\n",
                "\n",
                "This highlights some of the problems to take into account:\n",
                "\n",
                "**BPD:**\n",
                "1. BPD measures likelihood, which doesn't always correlate with sample quality in diffusion models\n",
                "2. As the model focuses on generating clear digit patterns, it may actually assign lower likelihood to some variations in the real data distribution\n",
                "3. Diffusion models can exhibit the \"likelihood training paradox\" where improved sample quality comes at the cost of worse likelihood scores\n",
                "\n",
                "**IS:**\n",
                "1. IS measures both quality and diversity simultaneously\n",
                "2. As training progresses, your model may be generating more accurate digits but with less stylistic variation\n",
                "3. The Inception network wasn't designed for MNIST-type images, making IS less reliable for digit evaluation\n",
                "\n",
                "This pattern of inconsistent metrics despite visual improvement is well-documented. Here's what should be taken into consideration:\n",
                "\n",
                "1. FID is the most reliable metric for grayscale diffusion and shows clear improvement\n",
                "2. Visual inspection remains crucial for evaluating digit generation quality\n",
                "3. BPD in particular can be misleading for evaluating sample quality in diffusion models\n",
                "\n",
                "Each problem can be solved through various alternatives. For example, to test digit quality, a custom metric that relies on OCR (Optical Character Recognition) to try to read the numbers would produce results more similar to human evaluation."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3b0c059a",
            "metadata": {},
            "source": [
                "### **Creating Custom Metrics**"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5a4c8c51",
            "metadata": {},
            "source": [
                "Custom metrics can be created by inheriting from `BaseMetric`. The methods that must be implemented are `__call__`, `name` and `is_lower_better`."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2826ad81",
            "metadata": {},
            "source": [
                "#### Implementation Example (OCR Metric for MNIST)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "199c9df2",
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image\n",
                "import easyocr\n",
                "\n",
                "class DigitOCRMetric(BaseMetric):\n",
                "    def __init__(self,\n",
                "                 model: GenerativeModel,\n",
                "                 digit: Union[int, str] = 3,\n",
                "                 display: bool = False # Added as part of the demonstration in this notebook (a real implementation would not include this nor any of the code to display the images)\n",
                "                 ):\n",
                "        super().__init__(model)\n",
                "        self.digit = str(digit)\n",
                "        self.display = display\n",
                "        self.reader = easyocr.Reader(['en'])\n",
                "\n",
                "    def config(self) -> dict:\n",
                "        return {\n",
                "            \"digit\": self.digit\n",
                "        }\n",
                "\n",
                "    @property\n",
                "    def name(self) -> str:\n",
                "        return f\"Digit {self.digit} OCR Accuracy\"\n",
                "\n",
                "    @property\n",
                "    def is_lower_better(self) -> bool:\n",
                "        return False\n",
                "\n",
                "    def _batch_to_pil(self, batch: Tensor) -> list[Image.Image]:\n",
                "        batch = batch.clamp(0, 1).mul(255).to(torch.uint8)\n",
                "        imgs = []\n",
                "        for img in batch:\n",
                "            if img.shape[0] == 1:\n",
                "                arr = img[0].cpu().numpy()\n",
                "                pil = Image.fromarray(arr, mode=\"L\")\n",
                "            else:\n",
                "                arr = img.permute(1, 2, 0).cpu().numpy()\n",
                "                pil = Image.fromarray(arr)\n",
                "            imgs.append(pil.convert(\"L\"))\n",
                "        return imgs\n",
                "\n",
                "    def __call__(self,\n",
                "                 _,\n",
                "                 generated: Union[Tensor, torch.utils.data.Dataset],\n",
                "                 *args,\n",
                "                 **kwargs) -> float:\n",
                "\n",
                "        if not isinstance(generated, Tensor):\n",
                "            dl = DataLoader(generated, batch_size=64, shuffle=False)\n",
                "        else:\n",
                "            dl = [(generated, )]\n",
                "\n",
                "        total = 0\n",
                "        correct = 0\n",
                "        outlines = []\n",
                "\n",
                "        for batch_tuple in dl:\n",
                "            batch = batch_tuple[0] if isinstance(batch_tuple, (list, tuple)) else batch_tuple\n",
                "            batch = batch.to(\"cpu\")\n",
                "            pil_images = self._batch_to_pil(batch)\n",
                "            batch_correct = []\n",
                "\n",
                "            for img in pil_images:\n",
                "                img_np = np.array(img)\n",
                "\n",
                "                result = self.reader.readtext(img_np)\n",
                "                text = ''.join([word_info[1] for word_info in result])\n",
                "                is_correct = self.digit in text\n",
                "                batch_correct.append(is_correct)\n",
                "                if is_correct:\n",
                "                    correct += 1\n",
                "            total += len(pil_images)\n",
                "\n",
                "            if self.display:\n",
                "                outlines.append((batch, batch_correct))\n",
                "\n",
                "        acc = correct / total if total > 0 else float(\"nan\")\n",
                "\n",
                "        if self.display and outlines:\n",
                "            outlined_batches = []\n",
                "            for batch, corr in outlines:\n",
                "                b = batch\n",
                "                if b.shape[1] == 1:\n",
                "                    b = b.repeat(1, 3, 1, 1)\n",
                "                for i, right in enumerate(corr):\n",
                "                    color = torch.tensor([0, 255, 0], dtype=torch.uint8) if right else torch.tensor([255, 0, 0], dtype=torch.uint8)\n",
                "                    b[i, :, 0, :] = color[:, None]\n",
                "                    b[i, :, -1, :] = color[:, None]\n",
                "                    b[i, :, :, 0] = color[:, None]\n",
                "                    b[i, :, :, -1] = color[:, None]\n",
                "                outlined_batches.append(b)\n",
                "            generated_with_outline = torch.cat(outlined_batches, dim=0)\n",
                "            display_images(generated_with_outline)\n",
                "\n",
                "        return acc"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ae7d06a",
            "metadata": {},
            "outputs": [],
            "source": [
                "scores_mnist_ocr = {}\n",
                "\n",
                "for model in trained_models_mnist:\n",
                "    metrics = [\n",
                "        DigitOCRMetric(model, digit=digit, display=True)\n",
                "    ]\n",
                "    samples = model.generate(16, seed=seed)\n",
                "    scores = model.score(data_mnist_test, samples, metrics=metrics)\n",
                "    for score in scores:\n",
                "        if score not in scores_mnist_ocr:\n",
                "            scores_mnist_ocr[score] = []\n",
                "        scores_mnist_ocr[score].append(scores[score])\n",
                "\n",
                "plot_scores(scores_mnist_ocr, metrics, \"MNIST - Scores vs Training Epochs\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
