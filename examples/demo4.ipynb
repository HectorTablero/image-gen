{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TÃ­tulo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./..')\n",
    "\n",
    "from image_gen import GenerativeModel\n",
    "from image_gen.diffusion import VarianceExploding, VariancePreserving, SubVariancePreserving\n",
    "from image_gen.noise import LinearNoiseSchedule, CosineNoiseSchedule\n",
    "from image_gen.samplers import EulerMaruyama, ExponentialIntegrator, ODEProbabilityFlow, PredictorCorrector\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model = \"ve\"\n",
    "noise_schedule = \"l\"\n",
    "sampler = \"euler\"\n",
    "\n",
    "schedule_map = {\n",
    "    \"l\": LinearNoiseSchedule(beta_min=0.0001, beta_max=10),\n",
    "    \"c\": CosineNoiseSchedule(beta_max=0.9999)\n",
    "}\n",
    "diffusion_map = {\n",
    "    \"ve\": VarianceExploding,\n",
    "    \"vp\": VariancePreserving,\n",
    "    \"svp\": SubVariancePreserving\n",
    "}\n",
    "sampler_map = {\n",
    "    \"euler\": EulerMaruyama,\n",
    "    \"exp\": ExponentialIntegrator,\n",
    "    \"ode\": ODEProbabilityFlow,\n",
    "    \"pc\": PredictorCorrector\n",
    "}\n",
    "\n",
    "model = GenerativeModel(\n",
    "    diffusion=diffusion_map.get(diffusion_model),\n",
    "    sampler=sampler_map.get(sampler),\n",
    "    noise_schedule=schedule_map.get(noise_schedule)\n",
    ")\n",
    "\n",
    "if diffusion_model != 've':\n",
    "    diffusion_model = f\"{diffusion_model}_{noise_schedule}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer',\n",
    "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar_dataset(class_id=None):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root='./data', \n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    if class_id is not None: \n",
    "        targets = torch.tensor(train_dataset.targets)\n",
    "        idx = (targets == class_id).nonzero().flatten()\n",
    "        \n",
    "        train_dataset = torch.utils.data.Subset(train_dataset, idx)\n",
    "        print(f\"Selected {len(train_dataset)} images of class: {CLASSES[class_id]}\")\n",
    "    \n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = None\n",
    "dataset = get_cifar_dataset(class_id=class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "model.train(dataset, epochs=epochs)\n",
    "class_name = \"_\" + CLASSES[class_id] if class_id is not None else \"\"\n",
    "model.save(f'cifar10{class_name}_{epochs}e_{diffusion_model}_{sampler}.pth')\n",
    "# model.load(f'cifar10_{CLASSES[class_id]}_{epochs}e_{diffusion_model}_{sampler}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 16\n",
    "samples = model.generate(n_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, n_images=4, contrast=1.0):\n",
    "    images = images[:n_images]  # Select only the first n_images\n",
    "    images = images.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
    "    images = (images + 1) / 2  # Scale from [-1,1] to [0,1]\n",
    "    \n",
    "    # Convert to grayscale intensity for proper contrast scaling\n",
    "    mean = images.mean(axis=(1, 2, 3), keepdims=True)\n",
    "    std = images.std(axis=(1, 2, 3), keepdims=True) + 1e-6  # Avoid division by zero\n",
    "\n",
    "    # Adjust contrast properly\n",
    "    images = mean + contrast * (images - mean)\n",
    "    images = np.clip(images, 0, 1)  # Ensure values remain in [0,1]\n",
    "\n",
    "    grid_size = int(np.sqrt(n_images))  # Ensure a square-like grid\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(4, 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, img in enumerate(images):\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cifar_images(dataset, n_images=4):\n",
    "    fig, axes = plt.subplots(int(np.sqrt(n_images)), int(np.sqrt(n_images)), figsize=(4, 4))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_images):\n",
    "        img, label = dataset[i]  # Get image and label\n",
    "        img = img.permute(1, 2, 0).numpy()  # Convert to (H, W, C)\n",
    "        img = (img + 1) / 2  # Rescale from [-1, 1] to [0, 1]\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cifar_images(dataset, n_images=n_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(samples, n_images=n_images, contrast=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
