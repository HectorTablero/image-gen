{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2d0fc1a",
   "metadata": {},
   "source": [
    "<pre style=\"text-align: right; width: 100%; font-size: 0.75em; line-height: 0.75em;\">\n",
    "+ ------------------------- + <br>\n",
    "| 20/04/2025                | <br>\n",
    "| Héctor Tablero Díaz       | <br>\n",
    "| Álvaro Martínez Gamo      | <br>\n",
    "+ ------------------------- + \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afee7ef",
   "metadata": {},
   "source": [
    "# **Diffusers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf439bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hecto\\Desktop\\Uni\\AAUTO 3\\Proyecto\\examples\\..\\image_gen\\samplers\\euler_maruyama.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./..')\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from image_gen import GenerativeModel\n",
    "from image_gen.samplers import EulerMaruyama\n",
    "from image_gen.diffusion import VarianceExploding, VariancePreserving, SubVariancePreserving, BaseDiffusion\n",
    "from image_gen.noise import LinearNoiseSchedule\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from image_gen.visualization import display_images, create_evolution_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee5082",
   "metadata": {},
   "source": [
    "The diffusers determine the way that noise is applied. The default classes are `VarianceExploding`, `VariancePreserving` and `SubVariancePreserving`, with the last 2 being Ornstein-Uhlenbeck processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc016b",
   "metadata": {},
   "source": [
    "### **Differences Between Diffusers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f6f2d",
   "metadata": {},
   "source": [
    "We can see the outputs of the different models and compare with each other.\n",
    "\n",
    "The first step is to get the dataset and define the global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9834e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the common variables\n",
    "epochs = 250\n",
    "digit = 3\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ca2386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# Select a subset to speed up the training process\n",
    "indices_digit = torch.where(data.targets == digit)[0]\n",
    "data = Subset(data, indices_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214e9a8",
   "metadata": {},
   "source": [
    "For convenience, we will create a function that includes initializing the model, training and generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffusion_demo(diffusion_type, num_samples=16, **kwargs):\n",
    "    \"\"\"\n",
    "    Demonstrates the diffusion process for a given diffusion type.\n",
    "    \"\"\"\n",
    "    DIFFUSION_CODES = {\n",
    "        VarianceExploding: \"ve\",\n",
    "        VariancePreserving: \"vp-lin\",\n",
    "        SubVariancePreserving: \"svp-lin\"\n",
    "    }\n",
    "\n",
    "    model = GenerativeModel(diffusion=diffusion_type, noise_schedule=LinearNoiseSchedule, sampler=EulerMaruyama)\n",
    "    \n",
    "    filename = f'saved_models/mnist_{digit}_{DIFFUSION_CODES[model.diffusion.__class__]}_euler_{epochs}e.pth'\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        model.load(filename)\n",
    "    else:\n",
    "        model.train(data, epochs=epochs)\n",
    "        # Tip: Save the models for them to be accessible through the dashboard\n",
    "        model.save(filename)\n",
    "\n",
    "    samples = model.generate(num_samples, **kwargs)\n",
    "    display_images(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_demo(VarianceExploding, num_samples=16, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c582cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_demo(VariancePreserving, num_samples=16, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf298dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_demo(SubVariancePreserving, num_samples=16, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895913ea",
   "metadata": {},
   "source": [
    "As it can be seen from these examples, `VarianceExploding` is the fastest to train, followed by `VariancePreserving` and lastly `SubVariancePreserving`, which requires a lot more epochs to produce good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bec4c02",
   "metadata": {},
   "source": [
    "### **Creating Custom Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f72ab",
   "metadata": {},
   "source": [
    "Custom diffusers can be created by inheriting from `BaseDiffusion`. The methods that must be implemented are `forward_sde` and `forward_process`.\n",
    "\n",
    "It is currently not supported to load models with a custom diffuser, but it is highly recommended that they implement a `config` method for future updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73608761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDiffuser(BaseDiffusion):\n",
    "    def forward_sde(self, x: Tensor, t: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        ...\n",
    "\n",
    "    def forward_process(self, x0: Tensor, t: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
